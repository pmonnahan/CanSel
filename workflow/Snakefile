# Load modules
import glob
import os
import subprocess
import pdb


# Get the date
from datetime import datetime
i = datetime.now()
TIME = i.strftime('%Y-%m-%d')

# Specify config file
configfile: "workflow/config.yml"

# Parse config.yml file
VCF = config['vcfs']['1000g']
POPKEY = config['pop_key']
NSTATS = config['nucleotide_stats']
HSTATS = config['haplotype_stats']
REFPOP = config['reference_pop']
QUERY = config['query_pops']
CHROMS = VCF.keys()
VENV = config['python_virtual_env']
WSIZE = config['window_size']
GMAP = config['genetic_map']

if QUERY == 'all':
    POPS = []
    with open(POPKEY, 'r') as pop_file:
        for i, line in enumerate(pop_file):
            pop = line.strip().split()[1]
            if i != 0 and pop != '':
                POPS.append(pop)
    POPS = list(set(POPS))
else:
    POPS = QUERY.split(",")

SDS_POPS = []
for spop in config['SDS']['gamma_shapes'].keys():
    SDS_POPS += config['SDS']['gamma_shapes'][spop]['pops'].strip().split(",")

# Make subdirectories
directories = ["data","nucleotide_stats","haplotype_stats","accessory","OandE","multilocus_stats"]
for dir in directories:
    if not os.path.exists(dir): os.mkdir(dir)

localrules: all, concatenate_results, clean

CONDA = f'source /panfs/roc/msisoft/anaconda/anaconda3-2018.12/bin/activate; conda activate {VENV}; export PATH=$PATH:/panfs/roc/msisoft/anaconda/anaconda3-2018.12/bin/'

def get_SDS_input(wildcards):
    in_files = glob.glob("multilocus_stats/*")

rule all:
    input:
        expand(f"data/ZarrFile/{{chrom}}/calldata/GT/0.0.0", chrom=CHROMS),
        expand(f"nucleotide_stats/{{Pop}}.chr{{chrom}}.nwn.{{metric1}}.csv", Pop=POPS, chrom=CHROMS, metric1=NSTATS['within_pop'].split(",")),
        expand(f"nucleotide_stats/{{Pop}}.chr{{chrom}}.nbn.{{metric2}}.csv", Pop=POPS, chrom=CHROMS, metric2=NSTATS['between_pop'].split(",")),
        expand(f"haplotype_stats/{{Pop}}.chr{{chrom}}.hwn.{{metric3}}.csv", Pop=POPS, chrom=CHROMS, metric3=HSTATS['within_pop'].split(",")),
        expand(f"haplotype_stats/{{Pop}}.chr{{chrom}}.hbn.{{metric4}}.csv", Pop=POPS, chrom=CHROMS, metric4=HSTATS['between_pop'].split(",")),
        expand(f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS.out", Pop=SDS_POPS, chrom=CHROMS),
        expand(f"accessory/polarization_key.chr{{chrom}}", chrom=CHROMS),
        "AllPops.NucStats.csv.gz", "AllPops.HapStats.csv.gz"

rule clean:
    shell:
        "rm data/*; rm nucleotide_stats/*; rm haplotype_stats/*; rm accessory/*; rm OandE/*"

rule filter_input:
    input: vcf=lambda wildcards: VCF[wildcards.chrom]
    output: "data/chrom{chrom}.vcf.gz"
    shell:
        f"module load bcftools; zcat {{input.vcf}} | cut -f 3 | sort | uniq -d | uniq > accessory/dup_vars{{wildcards.chrom}}.txt; bcftools view --types snps {{input.vcf}} -e \"F_MISSING>{config['input_filters']['missingness']}\" | bcftools norm -d all -m + | bcftools view --exclude \"ID==@accessory/dup_vars{{wildcards.chrom}}.txt\" --max-alleles 2 -Oz -o data/chrom{{wildcards.chrom}}.vcf.gz"

rule convert_vcf_to_zarr:
    input: "data/chrom{chrom}.vcf.gz"
    output: "data/ZarrFile/{chrom}/calldata/GT/0.0.0"
    shell: f"{CONDA}; python scripts/convert_vcf.py -vcf {{input}} -name {{wildcards.chrom}} -o data/ZarrFile"

#TODO: add SNP numbers for nstat windows
rule calculate_within_population_nucleotide_stats:
    input: "data/ZarrFile/{chrom}/calldata/GT/0.0.0"
    output: f"nucleotide_stats/{{Pop}}.chr{{chrom}}.nwn.{{metric1}}.csv"
    shell: f"{CONDA}; python scripts/NucStats.py -z data/ZarrFile -p {{wildcards.Pop}} -p2 None -k {POPKEY} -c {{wildcards.chrom}} -s {{wildcards.metric1}} -w {WSIZE} -o {{output}}"

rule calculate_between_population_nucleotide_stats:
    input: "data/ZarrFile/{chrom}/calldata/GT/0.0.0"
    output: f"nucleotide_stats/{{Pop}}.chr{{chrom}}.nbn.{{metric2}}.csv"
    shell: f"{CONDA}; python scripts/NucStats.py -z data/ZarrFile -p {{wildcards.Pop}} -p2 {REFPOP} -k {POPKEY} -c {{wildcards.chrom}} -s {{wildcards.metric2}} -w {WSIZE} -o {{output}}"

rule make_polarization_key:
    input: "data/ZarrFile/{chrom}/calldata/GT/0.0.0"
    output: f"accessory/polarization_key.chr{{chrom}}"
    shell: f"{CONDA}; python scripts/polarization_key.py -i data/ZarrFile -o accessory/polarization_key.chr{{wildcards.chrom}} -c {{wildcards.chrom}} -a {config['vcfs']['AA_spec']}"

rule calculate_within_population_haplotype_stats:
    input: "data/ZarrFile/{chrom}/calldata/GT/0.0.0",
           f"accessory/polarization_key.chr{{chrom}}"
    output: f"haplotype_stats/{{Pop}}.chr{{chrom}}.hwn.{{metric3}}.csv"
    shell: f"{CONDA}; python scripts/HapStats.py -z data/ZarrFile -p {{wildcards.Pop}} -p2 None -k {POPKEY} -c {{wildcards.chrom}} -s {{wildcards.metric3}} -o {{output}} -P {{input[1]}} -m {GMAP} --standardize"

rule calculate_between_population_haplotype_stats:
    input: "data/ZarrFile/{chrom}/calldata/GT/0.0.0",
           f"accessory/polarization_key.chr{{chrom}}"
    output: f"haplotype_stats/{{Pop}}.chr{{chrom}}.hbn.{{metric4}}.csv"
    shell: f"{CONDA}; python scripts/HapStats.py -z data/ZarrFile -p {{wildcards.Pop}} -p2 {REFPOP} -k {POPKEY} -c {{wildcards.chrom}} -s {{wildcards.metric4}} -o {{output}} -P {{input[1]}} -m {GMAP} --standardize"

rule concatenate_results:
    input:
        expand(f"nucleotide_stats/{{Pop}}.chr{{chrom}}.nwn.{{metric1}}.csv", Pop=POPS, chrom=CHROMS, metric1=NSTATS['within_pop'].split(",")),
        expand(f"nucleotide_stats/{{Pop}}.chr{{chrom}}.nbn.{{metric2}}.csv", Pop=POPS, chrom=CHROMS, metric2=NSTATS['between_pop'].split(",")),
        expand(f"haplotype_stats/{{Pop}}.chr{{chrom}}.hwn.{{metric3}}.csv", Pop=POPS, chrom=CHROMS, metric3=HSTATS['within_pop'].split(",")),
        expand(f"haplotype_stats/{{Pop}}.chr{{chrom}}.hbn.{{metric4}}.csv", Pop=POPS, chrom=CHROMS, metric4=HSTATS['between_pop'].split(",")),
    output: "AllPops.NucStats.csv.gz", "AllPops.HapStats.csv.gz"
    run:
        shell("for f in nucleotide_stats/*nwn*.csv; do head -n 1 $f > header.csv; done")
        shell("for f in haplotype_stats/*hwn*.csv; do head -n 1 $f > header2.csv; done")
        shell("for f in nucleotide_stats/*csv; do tail -n +2 $f >> tmp.csv; done")
        shell("for f in haplotype_stats/*csv; do tail -n +2 $f >> tmp2.csv; done")
        shell("cat header.csv tmp.csv | gzip > AllPops.NucStats.csv.gz")
        shell("cat header2.csv tmp2.csv | gzip > AllPops.HapStats.csv.gz")
        shell("for f in {{1..22}}; do tail -n +2 nucleotide_stats/*chr${{f}}.*csv | grep -v nucleotide >> tmp${{f}}.nuc.csv; done")
        shell("for f in {{1..22}}; do tail -n +2 haplotype_stats/*chr${{f}}.*csv | grep -v haplotype >> tmp${{f}}.hap.csv; done")
        shell("for f in {{1..22}}; do cat header.csv tmp${{f}}.nuc.csv | gzip  > AllPops.chr${{f}}.nuc.csv.gz; done; rm header.csv; rm tmp*.nuc.csv")
        shell("for f in {{1..22}}; do cat header2.csv tmp${{f}}.hap.csv | gzip > AllPops.chr${{f}}.hap.csv.gz; done; rm header2.csv; rm tmp*.hap.csv")

# rule make_db:
#     input:
#         expand(f"nucleotide_stats/{{pop}}.chr{{chrom}}.nwn.{{metric1}}.csv", pop=POPS, chrom=CHROMS, metric1=NSTATS['within_pop'].split(",")),
#         expand(f"nucleotide_stats/{{pop}}.chr{{chrom}}.nbn.{{metric2}}.csv", pop=POPS, chrom=CHROMS, metric2=NSTATS['between_pop'].split(",")),
#         expand(f"haplotype_stats/{{pop}}.chr{{chrom}}.hwn.{{metric3}}.csv", pop=POPS, chrom=CHROMS, metric3=HSTATS['within_pop'].split(",")),
#         expand(f"haplotype_stats/{{pop}}.chr{{chrom}}.hbn.{{metric4}}.csv", pop=POPS, chrom=CHROMS, metric4=HSTATS['between_pop'].split(",")),
#     output: "cansel.db"
#     run:
#         for file in input:
#             if "nucleotide" in file:

# rule simulate_nulls:
# #     input:

# rule extract_singletons:
#     input: f"data/ZarrFile/{{chrom}}/calldata/GT/0.0.0", f"accessory/polarization_key.chr{{chrom}}"
#     output: f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS.sings.gz"#, f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS.snps.gz"
#     shell: f"{CONDA}; python scripts/extract_SDS_input.py -z data/ZarrFile -p {{wildcards.Pop}} -k {POPKEY} -c {{wildcards.chrom}} -P {{input[1]}} -o multilocus_stats/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS;"
#             f"gzip multilocus_stats/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS.sings; gzip multilocus_stats/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS.snps"
#

checkpoint extract_singletons:
    input: f"data/ZarrFile/{{chrom}}/calldata/GT/0.0.0", f"accessory/polarization_key.chr{{chrom}}"
    output: directory(f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS") #.sings.gz"#, f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS.snps.gz"
    shell: f"mkdir multilocus_stats/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS; {CONDA}; python scripts/extract_SDS_input.py -z data/ZarrFile -p {{wildcards.Pop}} -k {POPKEY} -c {{wildcards.chrom}} -P {{input[1]}} -s {config['SDS']['batch_size']} -o multilocus_stats/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS;"
           f"gzip multilocus_stats/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS.sings; " 
           f"gzip multilocus_stats/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS/{{wildcards.Pop}}.chr{{wildcards.chrom}}.SDS.*.snps"

rule calcSDS:
    input: f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS/{{Pop}}.chr{{chrom}}.SDS.sings.gz"#, f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS/{{Pop}}.chr{{chrom}}.{{file_num}}.SDS.snps.gz"
    output: f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS/{{Pop}}.chr{{chrom}}.SDS.{{file_num}}.out"
    params: pre = f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS/{{Pop}}.chr{{chrom}}.SDS"
    run:
        for gamma in config['SDS']['gamma_shapes'].keys():
            if wildcards.Pop in config['SDS']['gamma_shapes'][gamma]['pops']:
                gamma_file = config['SDS']['gamma_shapes'][gamma]['path']
                init = config['SDS']['gamma_shapes'][gamma]['init']
        if gamma_file:
            shell(f"{CONDA}; {config['SDS']['exec']} {{params.pre}}.sings.gz {{params.pre}}.{{wildcards.file_num}}.snps.gz {{params.pre}}.{{wildcards.file_num}}.obs {{params.pre}}.bound {gamma_file} {init} > {{output}}")
        else:
            print(f"Did not find gamma shapes path for population: {{wildcards.Pop}}")

def aggregate_SDS(wildcards):
    checkpoint_output = checkpoints.extract_singletons.get(**wildcards).output[0]
    inputs = expand(f'multilocus_stats/{wildcards.Pop}.chr{wildcards.chrom}.SDS/{wildcards.Pop}.chr{wildcards.chrom}.SDS.{{file_num}}.out',
           file_num=glob_wildcards(os.path.join(checkpoint_output, f'{wildcards.Pop}.chr{wildcards.chrom}.SDS.{{i}}.obs')).i)
    # print(inputs)
    return inputs

# # generate random number of files
# checkpoint scatter:
#     output:
#         directory('scatter')
#     shell:
#         '''
#         mkdir {output}
#         N=$(( $RANDOM % 10))
#         for j in $(seq 1 $N); do echo -n $j > {output}/$j.txt; done
#         '''
#
# # process these unknown number of files
# rule scatter_copy:
#     output:
#         txt = 'scatter_copy/{i}_copy.txt',
#     input:
#         txt = 'scatter/{i}.txt',
#     shell:
#         '''
#         cp -f {input.txt} {output.txt}
#         echo -n "_copy" >> {output.txt}
#         '''
# # process scatter_copy output
# rule scatter_copy_head:
#     output:
#         txt = 'scatter_copy_head/{i}_head.txt',
#     input:
#         txt = 'scatter_copy/{i}_copy.txt',
#     shell:
#         '''
#         cp -f {input.txt} {output.txt}
#         echo "_head" >> {output.txt}
#         '''
#
# # collect the results of processing unknown number of files
# # and merge them together into one file:
#
# def aggregate_input(wildcards):
#     '''
#     aggregate the file names of the random number of files
#     generated at the scatter step
#     '''
#     checkpoint_output = checkpoints.scatter.get(**wildcards).output[0]
#     return expand('scatter_copy_head/{i}_head.txt',
#            i=glob_wildcards(os.path.join(checkpoint_output, '{i}.txt')).i)
#
# rule scatter_copy_head_collect:
#     output:
#         combined = 'scatter_copy_head_collect/all.txt',
#     input:
#         aggregate_input
#     shell:
#         '''
#         cat {input} > {output.combined}
#         '''

# rule calcSDS:
#     input: f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS.sings.gz"#, f"multilocus_stats/{{Pop}}.chr{{chrom}}.{{file_num}}.SDS.snps.gz"
#     output: f"multilocus_stats/{{Pop}}.chr{{chrom}}.{{file_num}}.SDS.out"
#     params: pre = f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS"
#     run:
#         for gamma in config['SDS']['gamma_shapes'].keys():
#             if wildcards.Pop in config['SDS']['gamma_shapes'][gamma]['pops']:
#                 gamma_file = config['SDS']['gamma_shapes'][gamma]['path']
#                 init = config['SDS']['gamma_shapes'][gamma]['init']
#         if gamma_file:
#             shell(f"{CONDA}; {config['SDS']['exec']} {{params.pre}}.sings.gz {{params.pre}}.{{wildcards.file_num}}.snps.gz {{params.pre}}.obs {{params.pre}}.bound {gamma_file} {init} > {{output}}")
#         else:
#             print(f"Did not find gamma shapes path for population: {{wildcards.Pop}}")

rule catSDS:
    input: aggregate_SDS
    output: f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS.out"
    shell: 'head -n 1 {input[0]} > head.txt; tail -q -n +2 {input} > tail.txt; cat head.txt tail.txt > {output}; rm head.txt; rm tail.txt'

#NOT FINISHED.  Need to label with population.
rule callSDS:
    input: expand(f"multilocus_stats/{{Pop}}.chr{{chrom}}.SDS.out", Pop=POPS, chrom=CHROMS)
    output: ".SDS.txt"
    shell: "touch ./.SDS.txt"
